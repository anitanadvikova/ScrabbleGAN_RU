{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6+TOhKcmrgjvckQYOzE53",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitanadvikova/ScrabbleGAN_RU/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ki7KC1za9HAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0de5e55-2fda-476e-d446-0e34e5a13982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ScrabbleGAN' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/arshjot/ScrabbleGAN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUDtiflNEplV",
        "outputId": "41c2abfd-42bf-4cf7-e9b5-26c02741730e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip drive/MyDrive/RIMES.zip"
      ],
      "metadata": {
        "id": "eivr0T-CH6P8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Перетащить RIMES в data\n",
        "2.   Изменить конфиг\n",
        "\n",
        "```python\n",
        "lexicon_file = f'/content/drive/MyDrive/words_russian_5000.txt' #строка 23\n",
        "data_folder_path ='/content/ScrabbleGAN/data/RIMES/' #строка 6\n",
        "num_chars = 108 #строка 51\n",
        "```\n",
        "\n",
        "3.   Изменить **data/prepare_data** строки 123-149"
      ],
      "metadata": {
        "id": "LnYpbpdfRBTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create char_map using training labels\n",
        "with open(f'{data_folder_path}/ground_truth_training_icdar2011.tsv', 'rb') as f:\n",
        "  ids = f.read().decode('utf8')\n",
        "  partition_ids = [i.split()[0] for i in ids.splitlines() if len(i) > 1]\n",
        "  words_raw = [(' '.join(i.split()[1:])) for i in ids.splitlines() if len(i)> 1]\n",
        "# Get list of unique characters and create dictionary for mapping them to integer\n",
        "chars=[]\n",
        "for w_i in words_raw:\n",
        "  for i in w_i:\n",
        "    chars.append(i)\n",
        "chars=np.unique(chars)\n",
        "\n",
        "chars=np.unique(chars)\n",
        "char_map = {value: idx + 1 for (idx, value) in enumerate(chars)}\n",
        "char_map['<BLANK>'] = 0\n",
        "num_chars = len(char_map.keys())\n",
        "  \n",
        "# Extract IDs for required set\n",
        "with open(f'{data_folder_path}/ground_truth_{partition_name}_icdar2011.tsv', 'rb') as f:\n",
        "  ids = f.read().decode('utf8')\n",
        "  partition_ids = [i.split()[0] for i in ids.splitlines() if len(i) > 1]\n",
        "  words_raw = [(' '.join(i.split()[1:])) for i in ids.splitlines() if len(i)> 1]\n",
        "\n",
        "word_data = {}\n",
        "for img_path, label in zip(partition_ids, words_raw):\n",
        "    if len(label)!=0:\n",
        "      img_path = f'{data_folder_path}/{partition_name}/{img_path}'\n",
        "      img, valid_img = read_image(img_path, len(label), img_h, char_w)\n",
        "      img_id = img_path[img_path.rfind('/')+1:-5]\n",
        "      if valid_img:\n",
        "          try:\n",
        "              word_data[img_id] = [[char_map[char] for char in label], img]\n",
        "          except KeyError:\n",
        "              pass"
      ],
      "metadata": {
        "id": "GDE87zW4XTW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ScrabbleGAN/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLPhp4Uo4U57",
        "outputId": "99b607cf-8dd6-47aa-c253-da94b22fd5d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'ScrabbleGAN/data'\n",
            "/content/ScrabbleGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python prepare_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpW6EWMbXnRg",
        "outputId": "933fdb2d-1933-49aa-e4fe-945ae4f3b399"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Data:\n",
            "\n",
            "Number of images = 17913\n",
            "Number of unique characters = 108\n",
            "\n",
            "Data processing completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r \"/content/drive/MyDrive/RIMES_tr_data.zip\" \"RIMES_tr_data.pkl\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_eIdi6OQGWQ",
        "outputId": "63a9adaa-d94a-4699-fae1-3f49ef9e5ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: RIMES_tr_data.pkl (deflated 31%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ChlYnwf8gb",
        "outputId": "82061276-26c5-407a-81f3-41e6750b2d05"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ScrabbleGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Меняем `models/ScrabbleGAN.py`\n",
        "\n",
        "```python\n",
        "#строки 78-87\n",
        "fake_words = []\n",
        "        \n",
        "with open(cfg.lexicon_file, 'r') as f:\n",
        "          fake_words.extend(f.read().splitlines())\n",
        "        \n",
        "self.fake_words = fake_words \n",
        "```"
      ],
      "metadata": {
        "id": "1ob9md0FiWIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавляем в  `utils/training_utils.py`\n",
        "\n",
        "```python\n",
        "#строка 26\n",
        "def saved(self, model, epoch, G_opt, D_opt, R_opt, G_sch=None, D_sch=None, R_sch=None):\n",
        "        filename = os.path.join('/content/drive/MyDrive', f'model_checkpoint_epoch_{epoch}.pth.tar')\n",
        "        save_dict = {\n",
        "            'model': model.state_dict(),\n",
        "            'G_opt': G_opt.state_dict(),\n",
        "            'D_opt': D_opt.state_dict(),\n",
        "            'R_opt': R_opt.state_dict(),\n",
        "            'epoch': epoch,\n",
        "            'G_sch': G_sch.state_dict(),\n",
        "            'D_sch': D_sch.state_dict(),\n",
        "            'R_sch': R_sch.state_dict()\n",
        "        }\n",
        "        torch.save(save_dict, filename)\n",
        "```"
      ],
      "metadata": {
        "id": "ijwaGg0cWLab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавляем в  `train.py`\n",
        "\n",
        "```python\n",
        "#строка 254\n",
        "self.model_checkpoint.saved(self.model, epoch, self.G_optimizer, self.D_optimizer, self.R_optimizer,\n",
        "                                       *self.schedulers)\n",
        "```"
      ],
      "metadata": {
        "id": "iWp6xtueWmqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZdqkuFJYASJ",
        "outputId": "3658a410-86b6-4da3-c255-2a8807779c51"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loading Data \n",
            " Model: ScrabbleGAN \n",
            "NumExpr defaulting to 2 threads.\n",
            "Param count for Gs initialized parameters: 30869377\n",
            "Param count for Ds initialized parameters: 36398401\n",
            "ScrabbleGAN(\n",
            "  (R): Recognizer(\n",
            "    (convs): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (output): Linear(in_features=512, out_features=108, bias=True)\n",
            "    (prob): LogSoftmax(dim=2)\n",
            "  )\n",
            "  (G): Generator(\n",
            "    (activation): ReLU()\n",
            "    (shared): identity()\n",
            "    (linear): SNLinear(in_features=3456, out_features=8192, bias=True)\n",
            "    (blocks): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): GBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): ccbn(\n",
            "            out: 512, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=512, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=512, bias=False)\n",
            "          )\n",
            "          (bn2): ccbn(\n",
            "            out: 256, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): ModuleList(\n",
            "        (0): GBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): ccbn(\n",
            "            out: 256, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "          )\n",
            "          (bn2): ccbn(\n",
            "            out: 128, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): ModuleList(\n",
            "        (0): GBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (conv_sc): SNConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): ccbn(\n",
            "            out: 128, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "          )\n",
            "          (bn2): ccbn(\n",
            "            out: 64, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=64, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=64, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (output_layer): Sequential(\n",
            "      (0): bn()\n",
            "      (1): ReLU()\n",
            "      (2): SNConv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (D): Discriminator(\n",
            "    (activation): ReLU()\n",
            "    (blocks): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (conv1): SNConv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (1): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (conv1): SNConv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (2): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (conv1): SNConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (linear): SNLinear(in_features=1024, out_features=1, bias=True)\n",
            "    (embed): SNLinear(in_features=108, out_features=1024, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "2023-03-21 09:40:50.762408: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-21 09:40:52.045584: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-21 09:40:52.045734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-21 09:40:52.045755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            " Training \n",
            " Epoch [1/200] \n",
            "G = 2.454, D = 0.992, R_real = 26.031, R_fake = 4.425,  : 100% 2240/2240 [15:20<00:00,  2.43it/s]\n",
            "G = 2.454, D = 0.992, R_real = 26.031, R_fake = 4.425\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: культура  |  Predicted: куетура\n",
            "Recognizer predictions for fake images:\n",
            "Actual: на        |  Predicted: стыаыыыыыыыыыыь\n",
            "Actual: вместе    |  Predicted: беыыямлллллля\n",
            "Actual: Качканар  |  Predicted: тото\n",
            "Actual: для       |  Predicted: т\n",
            " Epoch [2/200] \n",
            "G = 3.444, D = 0.168, R_real = 9.317, R_fake = 1.457,  : 100% 2240/2240 [15:12<00:00,  2.46it/s]\n",
            "G = 3.444, D = 0.168, R_real = 9.317, R_fake = 1.457\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: этно-  |  Predicted: 2тко\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Выхоложенный)  |  Predicted: селотчлллоя\n",
            "Actual: взбадриваемся  |  Predicted: Оедазтиваетло-дд\n",
            "Actual: воскресенье    |  Predicted: оостресетое\n",
            "Actual: Белгородская   |  Predicted: Геля-рслка\n",
            " Epoch [3/200] \n",
            "G = 2.919, D = 0.121, R_real = 6.303, R_fake = 0.841,  : 100% 2240/2240 [15:10<00:00,  2.46it/s]\n",
            "G = 2.919, D = 0.121, R_real = 6.303, R_fake = 0.841\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: развития  |  Predicted: развитие\n",
            "Recognizer predictions for fake images:\n",
            "Actual: 11:22:16           |  Predicted: 7 эбтэ я\n",
            "Actual: что                |  Predicted: гто\n",
            "Actual: погода             |  Predicted: почода\n",
            "Actual: НЕПРИМИРИМЕЙШИМИ]  |  Predicted: Увтйсюйслвяамючд\n",
            " Epoch [4/200] \n",
            "G = 3.055, D = 0.105, R_real = 4.923, R_fake = 0.762,  : 100% 2240/2240 [15:11<00:00,  2.46it/s]\n",
            "G = 3.055, D = 0.105, R_real = 4.923, R_fake = 0.762\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: достигает  |  Predicted: ростичаег\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Раздернута!.    |  Predicted: Газдернутат.\n",
            "Actual: Заглатываемом]  |  Predicted: 2аглатываетойд\n",
            "Actual: задолго         |  Predicted: задолио\n",
            "Actual: Накапливаемые.  |  Predicted: 1акатливаельые\n",
            " Epoch [5/200] \n",
            "G = 3.231, D = 0.102, R_real = 3.908, R_fake = 0.933,  : 100% 2240/2240 [15:14<00:00,  2.45it/s]\n",
            "G = 3.231, D = 0.102, R_real = 3.908, R_fake = 0.933\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: 1857  |  Predicted: со\n",
            "Recognizer predictions for fake images:\n",
            "Actual: что              |  Predicted: Утр\n",
            "Actual: формулирующих    |  Predicted: р5разрар9укцаг\n",
            "Actual: макетироваться!  |  Predicted: ра8л8тирваться\n",
            "Actual: Саха             |  Predicted: За97а\n",
            " Epoch [6/200] \n",
            "G = 3.727, D = 0.073, R_real = 3.101, R_fake = 1.593,  : 100% 2240/2240 [15:07<00:00,  2.47it/s]\n",
            "G = 3.727, D = 0.073, R_real = 3.101, R_fake = 1.593\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: работником  |  Predicted: рабжнйком\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Хронисты       |  Predicted: беронисты\n",
            "Actual: Бугорчатым     |  Predicted: Вучориатим\n",
            "Actual: 23.12.1985     |  Predicted: Г. т2 лз5\n",
            "Actual: Расцениваться  |  Predicted: Гасцениваться\n",
            " Epoch [7/200] \n",
            "G = 4.129, D = 0.048, R_real = 2.398, R_fake = 2.681,  : 100% 2240/2240 [15:13<00:00,  2.45it/s]\n",
            "G = 4.129, D = 0.048, R_real = 2.398, R_fake = 2.681\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: карте.  |  Predicted: жарте.\n",
            "Recognizer predictions for fake images:\n",
            "Actual: 29.04.1971 0:00    |  Predicted: 20.0.и.19х1от0\n",
            "Actual: 18                 |  Predicted: 18\n",
            "Actual: ЛАТИНИЗИРОВАННОМУ  |  Predicted: 1Ата д9з39рСоА1У0ит)\n",
            "Actual: Карелия            |  Predicted: карелия\n",
            " Epoch [8/200] \n",
            "G = 4.129, D = 0.065, R_real = 1.853, R_fake = 2.390,  : 100% 2240/2240 [15:08<00:00,  2.46it/s]\n",
            "G = 4.129, D = 0.065, R_real = 1.853, R_fake = 2.390\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: помочь  |  Predicted: помочь\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Офтальмиею   |  Predicted: Вятальмнуею\n",
            "Actual: Вологодская  |  Predicted: Вологодская\n",
            "Actual: не           |  Predicted: ня\n",
            "Actual: рывок)       |  Predicted: рывок)\n",
            " Epoch [9/200] \n",
            "G = 4.265, D = 0.066, R_real = 1.459, R_fake = 1.371,  : 100% 2240/2240 [15:12<00:00,  2.46it/s]\n",
            "G = 4.265, D = 0.066, R_real = 1.459, R_fake = 1.371\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: -нормально  |  Predicted: -нормально\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Забайкальский  |  Predicted: Забйкальский\n",
            "Actual: но             |  Predicted: но\n",
            "Actual: мы             |  Predicted: мы\n",
            "Actual: играет         |  Predicted: играет\n",
            " Epoch [10/200] \n",
            "G = 4.231, D = 0.067, R_real = 1.176, R_fake = 1.561,  : 100% 2240/2240 [15:13<00:00,  2.45it/s]\n",
            "G = 4.231, D = 0.067, R_real = 1.176, R_fake = 1.561\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: непрерывна  |  Predicted: непроривна\n",
            "Recognizer predictions for fake images:\n",
            "Actual: 0                |  Predicted: О\n",
            "Actual: сего             |  Predicted: сего\n",
            "Actual: проверчены       |  Predicted: проверчены\n",
            "Actual: Десятилитровая.  |  Predicted: Десятмлитровыя.\n",
            " Epoch [11/200] \n",
            "G = 4.701, D = 0.054, R_real = 1.003, R_fake = 1.883,  : 100% 2240/2240 [15:12<00:00,  2.45it/s]\n",
            "G = 4.701, D = 0.054, R_real = 1.003, R_fake = 1.883\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: Поставим  |  Predicted: Поствим\n",
            "Recognizer predictions for fake images:\n",
            "Actual: 08.30.87           |  Predicted: Из.07\n",
            "Actual: ВОЕНИЗИРУЮЩЕЙСЯ).  |  Predicted: ВОсИиЖкруиаЕист,.\n",
            "Actual: 11                 |  Predicted: л1\n",
            "Actual: Бедняцкого         |  Predicted: Беднаикаго\n",
            " Epoch [12/200] \n",
            "G = 4.454, D = 0.109, R_real = 0.847, R_fake = 1.336,  : 100% 2240/2240 [15:13<00:00,  2.45it/s]\n",
            "G = 4.454, D = 0.109, R_real = 0.847, R_fake = 1.336\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: говорят  |  Predicted: говоре\n",
            "Recognizer predictions for fake images:\n",
            "Actual: прежние        |  Predicted: прежние\n",
            "Actual: 27             |  Predicted: 27\n",
            "Actual: судом          |  Predicted: сувом\n",
            "Actual: Калач-на-Дону  |  Predicted: калачжасДоня\n",
            " Epoch [13/200] \n",
            "G = 4.641, D = 0.067, R_real = 0.745, R_fake = 1.540,  : 100% 2240/2240 [15:13<00:00,  2.45it/s]\n",
            "G = 4.641, D = 0.067, R_real = 0.745, R_fake = 1.540\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: частей  |  Predicted: частей\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Краснодарский      |  Predicted: Криснодарский\n",
            "Actual: а                  |  Predicted: а\n",
            "Actual: Прободрствовавшем  |  Predicted: Прободр ствовавшем\n",
            "Actual: Ленинградская      |  Predicted: 1енинградская\n",
            " Epoch [14/200] \n",
            "G = 4.419, D = 0.078, R_real = 0.638, R_fake = 0.987,  : 100% 2240/2240 [15:15<00:00,  2.45it/s]\n",
            "G = 4.419, D = 0.078, R_real = 0.638, R_fake = 0.987\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: городским  |  Predicted: городским\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Разбалованной,  |  Predicted: Разбалованнойе,\n",
            "Actual: Трехстенным     |  Predicted: ГраеВстенным\n",
            "Actual: 0               |  Predicted: 8.\n",
            "Actual: что             |  Predicted: что\n",
            " Epoch [15/200] \n",
            "G = 4.672, D = 0.058, R_real = 0.554, R_fake = 1.374,  :  62% 1384/2240 [09:24<05:49,  2.45it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ScrabbleGAN/train.py\", line 277, in <module>\n",
            "    trainer.train()\n",
            "  File \"/content/ScrabbleGAN/train.py\", line 192, in train\n",
            "    for i, batch_items in enumerate(progbar):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1178, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 641, in __next__\n",
            "    return data\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/profiler.py\", line 493, in __exit__\n",
            "    torch.ops.profiler._record_function_exit(self.handle)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_ops.py\", line 442, in __call__\n",
            "    return self._op(*args, **kwargs or {})\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip \"weights/model_checkpoint_epoch_14.pth.tar.zip\" \"/content/drive/My Drive/\""
      ],
      "metadata": {
        "id": "HZnXdaSFUHzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f02eedf-2184-48de-aefd-3ae1bd18b83d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "zip error: Nothing to do! (weights/model_checkpoint_epoch_14.pth.tar.zip)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%rm -rf fid_calc\n",
        "!bash  python calculate_metrics.py -c '/content/ScrabbleGAN/weights/model_checkpoint_epoch_14.pth.tar'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-UnAdjWXaqd",
        "outputId": "24f6d79e-5f3b-4520-eb8a-c99e04e17bba"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating and saving fake images\n",
            "Model: ScrabbleGAN\n",
            "Param count for Gs initialized parameters: 30869377\n",
            "Param count for Ds initialized parameters: 36398401\n",
            "100% 50/50 [00:02<00:00, 20.24it/s]\n",
            "Sampling and saving real images\n",
            "100% 50/50 [00:00<00:00, 114.51it/s]\n",
            "/usr/bin/python3: No module named pytorch_fid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pytorch_fid '/content/ScrabbleGAN/fid_calc/real' '/content/ScrabbleGAN/fid_calc/fake'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQxgLiE_asn6",
        "outputId": "35fd4a20-7b36-47e4-ed25-393a95c02c5e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:00<00:00, 138MB/s]\n",
            "100% 1/1 [00:03<00:00,  3.61s/it]\n",
            "100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "FID:  225.24632311114516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDL8v2hbb640"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}