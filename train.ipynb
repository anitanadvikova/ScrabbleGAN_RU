{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzTcCnfsbYC+V3nN9YXdFH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitanadvikova/ScrabbleGAN_RU/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ki7KC1za9HAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed04e06-dfac-48d5-b080-c49a60b4b190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ScrabbleGAN'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 208 (delta 89), reused 173 (delta 57), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (208/208), 202.94 KiB | 11.94 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/arshjot/ScrabbleGAN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUDtiflNEplV",
        "outputId": "0d7b1a0e-0712-467b-d12c-8fcaf5d1d515"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip drive/MyDrive/RIMES.zip"
      ],
      "metadata": {
        "id": "eivr0T-CH6P8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Перетащить RIMES в data\n",
        "2.   Изменить конфиг\n",
        "\n",
        "```python\n",
        "lexicon_file = '/content/drive/MyDrive/words_russian_5000.txt'\n",
        "data_folder_path ='/content/ScrabbleGAN/data/RIMES/'. #строка 6\n",
        "num_chars = 108 #строка 51\n",
        "```\n",
        "\n",
        "3.   Изменить **data/prepare_data** строки 123-149"
      ],
      "metadata": {
        "id": "LnYpbpdfRBTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create char_map using training labels\n",
        "with open(f'{data_folder_path}/ground_truth_training_icdar2011.tsv', 'rb') as f:\n",
        "  ids = f.read().decode('utf8')\n",
        "  partition_ids = [i.split()[0] for i in ids.splitlines() if len(i) > 1]\n",
        "  words_raw = [(' '.join(i.split()[1:])) for i in ids.splitlines() if len(i)> 1]\n",
        "# Get list of unique characters and create dictionary for mapping them to integer\n",
        "chars=[]\n",
        "for w_i in words_raw:\n",
        "  for i in w_i:\n",
        "    chars.append(i)\n",
        "chars=np.unique(chars)\n",
        "\n",
        "chars=np.unique(chars)\n",
        "char_map = {value: idx + 1 for (idx, value) in enumerate(chars)}\n",
        "char_map['<BLANK>'] = 0\n",
        "num_chars = len(char_map.keys())\n",
        "  \n",
        "# Extract IDs for required set\n",
        "with open(f'{data_folder_path}/ground_truth_{partition_name}_icdar2011.tsv', 'rb') as f:\n",
        "  ids = f.read().decode('utf8')\n",
        "  partition_ids = [i.split()[0] for i in ids.splitlines() if len(i) > 1]\n",
        "  words_raw = [(' '.join(i.split()[1:])) for i in ids.splitlines() if len(i)> 1]\n",
        "\n",
        "word_data = {}\n",
        "for img_path, label in zip(partition_ids, words_raw):\n",
        "    if len(label)!=0:\n",
        "      img_path = f'{data_folder_path}/{partition_name}/{img_path}'\n",
        "      img, valid_img = read_image(img_path, len(label), img_h, char_w)\n",
        "      img_id = img_path[img_path.rfind('/')+1:-5]\n",
        "      if valid_img:\n",
        "          try:\n",
        "              word_data[img_id] = [[char_map[char] for char in label], img]\n",
        "          except KeyError:\n",
        "              pass"
      ],
      "metadata": {
        "id": "GDE87zW4XTW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ScrabbleGAN/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLPhp4Uo4U57",
        "outputId": "cd93212c-0161-4e7a-8cc8-90f37b5a3fd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ScrabbleGAN/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python prepare_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpW6EWMbXnRg",
        "outputId": "d2d3ce4f-a8ba-4390-a79c-d9b636baf60c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Data:\n",
            "\n",
            "Number of images = 17913\n",
            "Number of unique characters = 108\n",
            "\n",
            "Data processing completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ChlYnwf8gb",
        "outputId": "b20823e2-40a3-4f5c-fd66-034cf72b496d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ScrabbleGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Меняем `models/ScrabbleGAN.py`\n",
        "\n",
        "```python\n",
        "#строки 78-87\n",
        "fake_words = []\n",
        "        \n",
        "with open(cfg.lexicon_file, 'r') as f:\n",
        "          fake_words.extend(f.read().splitlines())\n",
        "        \n",
        "self.fake_words = fake_words \n",
        "```"
      ],
      "metadata": {
        "id": "1ob9md0FiWIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZdqkuFJYASJ",
        "outputId": "218dccfb-81a1-44c5-ec38-2d12b6bfcd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loading Data \n",
            " Model: ScrabbleGAN \n",
            "NumExpr defaulting to 2 threads.\n",
            "Param count for Gs initialized parameters: 30869377\n",
            "Param count for Ds initialized parameters: 36398401\n",
            "ScrabbleGAN(\n",
            "  (R): Recognizer(\n",
            "    (convs): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (output): Linear(in_features=512, out_features=108, bias=True)\n",
            "    (prob): LogSoftmax(dim=2)\n",
            "  )\n",
            "  (G): Generator(\n",
            "    (activation): ReLU()\n",
            "    (shared): identity()\n",
            "    (linear): SNLinear(in_features=3456, out_features=8192, bias=True)\n",
            "    (blocks): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): GBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): ccbn(\n",
            "            out: 512, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=512, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=512, bias=False)\n",
            "          )\n",
            "          (bn2): ccbn(\n",
            "            out: 256, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): ModuleList(\n",
            "        (0): GBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): ccbn(\n",
            "            out: 256, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "          )\n",
            "          (bn2): ccbn(\n",
            "            out: 128, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): ModuleList(\n",
            "        (0): GBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (conv_sc): SNConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): ccbn(\n",
            "            out: 128, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "          )\n",
            "          (bn2): ccbn(\n",
            "            out: 64, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=64, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=64, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (output_layer): Sequential(\n",
            "      (0): bn()\n",
            "      (1): ReLU()\n",
            "      (2): SNConv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (D): Discriminator(\n",
            "    (activation): ReLU()\n",
            "    (blocks): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (conv1): SNConv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (1): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (conv1): SNConv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (2): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (conv1): SNConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (linear): SNLinear(in_features=1024, out_features=1, bias=True)\n",
            "    (embed): SNLinear(in_features=108, out_features=1024, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "2023-03-20 15:29:30.439054: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-20 15:29:32.387976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-20 15:29:32.388138: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-20 15:29:32.388159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            " Training \n",
            " Epoch [1/200] \n",
            "G = 2.263, D = 1.830, R_real = 33.819, R_fake = 5.155,  :  41% 920/2240 [06:11<07:16,  3.02it/s]"
          ]
        }
      ]
    }
  ]
}