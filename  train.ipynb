{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGvDqDHw68jYJ9j3o3jfUA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitanadvikova/ScrabbleGAN_RU/blob/main/%20train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ki7KC1za9HAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe97349-573b-4f5b-c5a4-840246721d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ScrabbleGAN'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 208 (delta 89), reused 173 (delta 57), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (208/208), 202.94 KiB | 15.61 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/arshjot/ScrabbleGAN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUDtiflNEplV",
        "outputId": "24e4abc4-79ca-4761-fa65-e15a6df2f864"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip drive/MyDrive/RIMES.zip"
      ],
      "metadata": {
        "id": "eivr0T-CH6P8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Перетащить RIMES в data\n",
        "2.   Изменить конфиг\n",
        "\n",
        "```python\n",
        "lexicon_file = f'/content/drive/MyDrive/words_russian_5000.txt' #строка 23\n",
        "data_folder_path ='/content/ScrabbleGAN/data/RIMES/'. #строка 6\n",
        "num_chars = 108 #строка 51\n",
        "```\n",
        "\n",
        "3.   Изменить **data/prepare_data** строки 123-149"
      ],
      "metadata": {
        "id": "LnYpbpdfRBTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create char_map using training labels\n",
        "with open(f'{data_folder_path}/ground_truth_training_icdar2011.tsv', 'rb') as f:\n",
        "  ids = f.read().decode('utf8')\n",
        "  partition_ids = [i.split()[0] for i in ids.splitlines() if len(i) > 1]\n",
        "  words_raw = [(' '.join(i.split()[1:])) for i in ids.splitlines() if len(i)> 1]\n",
        "# Get list of unique characters and create dictionary for mapping them to integer\n",
        "chars=[]\n",
        "for w_i in words_raw:\n",
        "  for i in w_i:\n",
        "    chars.append(i)\n",
        "chars=np.unique(chars)\n",
        "\n",
        "chars=np.unique(chars)\n",
        "char_map = {value: idx + 1 for (idx, value) in enumerate(chars)}\n",
        "char_map['<BLANK>'] = 0\n",
        "num_chars = len(char_map.keys())\n",
        "  \n",
        "# Extract IDs for required set\n",
        "with open(f'{data_folder_path}/ground_truth_{partition_name}_icdar2011.tsv', 'rb') as f:\n",
        "  ids = f.read().decode('utf8')\n",
        "  partition_ids = [i.split()[0] for i in ids.splitlines() if len(i) > 1]\n",
        "  words_raw = [(' '.join(i.split()[1:])) for i in ids.splitlines() if len(i)> 1]\n",
        "\n",
        "word_data = {}\n",
        "for img_path, label in zip(partition_ids, words_raw):\n",
        "    if len(label)!=0:\n",
        "      img_path = f'{data_folder_path}/{partition_name}/{img_path}'\n",
        "      img, valid_img = read_image(img_path, len(label), img_h, char_w)\n",
        "      img_id = img_path[img_path.rfind('/')+1:-5]\n",
        "      if valid_img:\n",
        "          try:\n",
        "              word_data[img_id] = [[char_map[char] for char in label], img]\n",
        "          except KeyError:\n",
        "              pass"
      ],
      "metadata": {
        "id": "GDE87zW4XTW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ScrabbleGAN/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLPhp4Uo4U57",
        "outputId": "4bfa2941-81f4-4497-e9d2-a79382932178"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ScrabbleGAN/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python prepare_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpW6EWMbXnRg",
        "outputId": "a3d8bfc6-8df9-4318-b7d6-e766e5852f48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Data:\n",
            "\n",
            "Number of images = 17913\n",
            "Number of unique characters = 108\n",
            "\n",
            "Data processing completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"/content/drive/MyDrive/RIMES_tr_data.zip\" \"RIMES_tr_data.pkl\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_eIdi6OQGWQ",
        "outputId": "63a9adaa-d94a-4699-fae1-3f49ef9e5ff1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: RIMES_tr_data.pkl (deflated 31%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ChlYnwf8gb",
        "outputId": "a062f39e-42b8-450b-c1e7-06af11585063"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ScrabbleGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Меняем `models/ScrabbleGAN.py`\n",
        "\n",
        "```python\n",
        "#строки 78-87\n",
        "fake_words = []\n",
        "        \n",
        "with open(cfg.lexicon_file, 'r') as f:\n",
        "          fake_words.extend(f.read().splitlines())\n",
        "        \n",
        "self.fake_words = fake_words \n",
        "```"
      ],
      "metadata": {
        "id": "1ob9md0FiWIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZdqkuFJYASJ",
        "outputId": "bc189269-b15a-4c9d-e1e1-dd673bdfb07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loading Data \n",
            " Model: ScrabbleGAN \n",
            "NumExpr defaulting to 2 threads.\n",
            "Param count for Gs initialized parameters: 30869377\n",
            "Param count for Ds initialized parameters: 36398401\n",
            "ScrabbleGAN(\n",
            "  (R): Recognizer(\n",
            "    (convs): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (output): Linear(in_features=512, out_features=108, bias=True)\n",
            "    (prob): LogSoftmax(dim=2)\n",
            "  )\n",
            "  (G): Generator(\n",
            "    (activation): ReLU()\n",
            "    (shared): identity()\n",
            "    (linear): SNLinear(in_features=3456, out_features=8192, bias=True)\n",
            "    (blocks): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): GBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): ccbn(\n",
            "            out: 512, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=512, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=512, bias=False)\n",
            "          )\n",
            "          (bn2): ccbn(\n",
            "            out: 256, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): ModuleList(\n",
            "        (0): GBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): ccbn(\n",
            "            out: 256, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=256, bias=False)\n",
            "          )\n",
            "          (bn2): ccbn(\n",
            "            out: 128, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): ModuleList(\n",
            "        (0): GBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (conv_sc): SNConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): ccbn(\n",
            "            out: 128, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=128, bias=False)\n",
            "          )\n",
            "          (bn2): ccbn(\n",
            "            out: 64, in: 32, cross_replica=False\n",
            "            (gain): SNLinear(in_features=32, out_features=64, bias=False)\n",
            "            (bias): SNLinear(in_features=32, out_features=64, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (output_layer): Sequential(\n",
            "      (0): bn()\n",
            "      (1): ReLU()\n",
            "      (2): SNConv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (D): Discriminator(\n",
            "    (activation): ReLU()\n",
            "    (blocks): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (conv1): SNConv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (1): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (conv1): SNConv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (2): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (conv1): SNConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv_sc): SNConv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): ModuleList(\n",
            "        (0): DBlock(\n",
            "          (activation): ReLU()\n",
            "          (conv1): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (linear): SNLinear(in_features=1024, out_features=1, bias=True)\n",
            "    (embed): SNLinear(in_features=108, out_features=1024, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "2023-03-20 23:21:31.408198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-20 23:21:33.395314: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-20 23:21:33.395449: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-20 23:21:33.395488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            " Training \n",
            " Epoch [1/200] \n",
            "G = 2.519, D = 1.012, R_real = 26.368, R_fake = 4.534,  : 100% 2240/2240 [15:11<00:00,  2.46it/s]\n",
            "G = 2.519, D = 1.012, R_real = 26.368, R_fake = 4.534\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: культура  |  Predicted: кутуа\n",
            "Recognizer predictions for fake images:\n",
            "Actual: на        |  Predicted: кдоддддддддддде\n",
            "Actual: вместе    |  Predicted: Поиьххххххх\n",
            "Actual: Качканар  |  Predicted: пньл\n",
            "Actual: для       |  Predicted: Памм\n",
            " Epoch [2/200] \n",
            "G = 2.967, D = 0.186, R_real = 9.729, R_fake = 1.425,  : 100% 2240/2240 [15:03<00:00,  2.48it/s]\n",
            "G = 2.967, D = 0.186, R_real = 9.729, R_fake = 1.425\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: этно-  |  Predicted: эно\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Выхоложенный)  |  Predicted: отолопнныб\n",
            "Actual: взбадриваемся  |  Predicted: е-бад-пиае\n",
            "Actual: воскресенье    |  Predicted: васкряаянее\n",
            "Actual: Белгородская   |  Predicted: эелеорадстае\n",
            " Epoch [3/200] \n",
            "G = 2.847, D = 0.125, R_real = 6.378, R_fake = 0.965,  : 100% 2240/2240 [14:59<00:00,  2.49it/s]\n",
            "G = 2.847, D = 0.125, R_real = 6.378, R_fake = 0.965\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: развития  |  Predicted: развитие\n",
            "Recognizer predictions for fake images:\n",
            "Actual: 11:22:16           |  Predicted: 119б75.е\n",
            "Actual: что                |  Predicted: что\n",
            "Actual: погода             |  Predicted: почода\n",
            "Actual: НЕПРИМИРИМЕЙШИМИ]  |  Predicted: хг)ы2кэб2а8ргкзу\n",
            " Epoch [4/200] \n",
            "G = 2.982, D = 0.096, R_real = 4.941, R_fake = 0.879,  : 100% 2240/2240 [14:59<00:00,  2.49it/s]\n",
            "G = 2.982, D = 0.096, R_real = 4.941, R_fake = 0.879\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: достигает  |  Predicted: достичает\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Раздернута!.    |  Predicted: Гарернутат\n",
            "Actual: Заглатываемом]  |  Predicted: далатываемом,\n",
            "Actual: задолго         |  Predicted: задолго\n",
            "Actual: Накапливаемые.  |  Predicted: Уакамливаемзе,\n",
            " Epoch [5/200] \n",
            "G = 2.997, D = 0.146, R_real = 3.917, R_fake = 1.078,  : 100% 2240/2240 [15:02<00:00,  2.48it/s]\n",
            "G = 2.997, D = 0.146, R_real = 3.917, R_fake = 1.078\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: 1857  |  Predicted: о7\n",
            "Recognizer predictions for fake images:\n",
            "Actual: что              |  Predicted: тто\n",
            "Actual: формулирующих    |  Predicted: 5рмул4ру5з4\n",
            "Actual: макетироваться!  |  Predicted: н8кети8веатьс5\n",
            "Actual: Саха             |  Predicted: З2\n",
            " Epoch [6/200] \n",
            "G = 3.371, D = 0.081, R_real = 3.045, R_fake = 1.373,  : 100% 2240/2240 [14:55<00:00,  2.50it/s]\n",
            "G = 3.371, D = 0.081, R_real = 3.045, R_fake = 1.373\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: работником  |  Predicted: рабоником\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Хронисты       |  Predicted: бронисты\n",
            "Actual: Бугорчатым     |  Predicted: ругорчатом\n",
            "Actual: 23.12.1985     |  Predicted: 2. 12.19.\n",
            "Actual: Расцениваться  |  Predicted: Касцениваюь ся\n",
            " Epoch [7/200] \n",
            "G = 3.719, D = 0.061, R_real = 2.357, R_fake = 1.376,  : 100% 2240/2240 [14:59<00:00,  2.49it/s]\n",
            "G = 3.719, D = 0.061, R_real = 2.357, R_fake = 1.376\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: карте.  |  Predicted: нартя\n",
            "Recognizer predictions for fake images:\n",
            "Actual: 29.04.1971 0:00    |  Predicted: 2.0лг.зго.ос.\n",
            "Actual: 18                 |  Predicted: \n",
            "Actual: ЛАТИНИЗИРОВАННОМУ  |  Predicted: Иат)1зто3т.)1.\n",
            "Actual: Карелия            |  Predicted: каретия\n",
            " Epoch [8/200] \n",
            "G = 4.087, D = 0.065, R_real = 1.794, R_fake = 1.867,  : 100% 2240/2240 [14:56<00:00,  2.50it/s]\n",
            "G = 4.087, D = 0.065, R_real = 1.794, R_fake = 1.867\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: помочь  |  Predicted: помочь\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Офтальмиею   |  Predicted: Онтольмиео\n",
            "Actual: Вологодская  |  Predicted: Боло 2одская\n",
            "Actual: не           |  Predicted: не\n",
            "Actual: рывок)       |  Predicted: рывокл\n",
            " Epoch [9/200] \n",
            "G = 4.216, D = 0.076, R_real = 1.403, R_fake = 1.709,  : 100% 2240/2240 [15:00<00:00,  2.49it/s]\n",
            "G = 4.216, D = 0.076, R_real = 1.403, R_fake = 1.709\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: -нормально  |  Predicted: -нормально\n",
            "Recognizer predictions for fake images:\n",
            "Actual: Забайкальский  |  Predicted: Затайкальский\n",
            "Actual: но             |  Predicted: но\n",
            "Actual: мы             |  Predicted: мы\n",
            "Actual: играет         |  Predicted: аграст\n",
            " Epoch [10/200] \n",
            "G = 4.230, D = 0.088, R_real = 1.109, R_fake = 1.288,  : 100% 2240/2240 [15:01<00:00,  2.48it/s]\n",
            "G = 4.230, D = 0.088, R_real = 1.109, R_fake = 1.288\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: непрерывна  |  Predicted: пепрорывна\n",
            "Recognizer predictions for fake images:\n",
            "Actual: 0                |  Predicted: о\n",
            "Actual: сего             |  Predicted: ск га\n",
            "Actual: проверчены       |  Predicted: проверчены\n",
            "Actual: Десятилитровая.  |  Predicted: ДесятилитрМвая.\n",
            " Epoch [11/200] \n",
            "G = 4.313, D = 0.069, R_real = 0.944, R_fake = 1.406,  : 100% 2240/2240 [15:01<00:00,  2.49it/s]\n",
            "G = 4.313, D = 0.069, R_real = 0.944, R_fake = 1.406\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: Поставим  |  Predicted: Поствим\n",
            "Recognizer predictions for fake images:\n",
            "Actual: 08.30.87           |  Predicted: т9.Р.97\n",
            "Actual: ВОЕНИЗИРУЮЩЕЙСЯ).  |  Predicted: ВОблзИР КдитПСтА.\n",
            "Actual: 11                 |  Predicted: 1\n",
            "Actual: Бедняцкого         |  Predicted: Бтедняцкого\n",
            " Epoch [12/200] \n",
            "G = 3.885, D = 0.109, R_real = 0.811, R_fake = 1.025,  : 100% 2240/2240 [15:01<00:00,  2.48it/s]\n",
            "G = 3.885, D = 0.109, R_real = 0.811, R_fake = 1.025\n",
            "\n",
            "Recognizer predictions for real images:\n",
            "Actual: говорят  |  Predicted: говорят\n",
            "Recognizer predictions for fake images:\n",
            "Actual: прежние        |  Predicted: прежние\n",
            "Actual: 27             |  Predicted: 22\n",
            "Actual: судом          |  Predicted: сувом\n",
            "Actual: Калач-на-Дону  |  Predicted: Калоачс-носДону\n",
            " Epoch [13/200] \n",
            "G = 3.956, D = 0.087, R_real = 0.674, R_fake = 0.936,  :  74% 1649/2240 [11:03<04:55,  2.00it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZnXdaSFUHzq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}